{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gmrou\\AppData\\Local\\Temp\\ipykernel_9616\\4219890672.py:25: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"GENRE\"] = data[\"GENRE\"].replace({\"M\": 0,\"F\":1})\n",
      "C:\\Users\\gmrou\\AppData\\Local\\Temp\\ipykernel_9616\\4219890672.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"PATHO_CORO\"] = data[\"PATHO_CORO\"].replace({\"NON\": 0,\"OUI\":1})\n",
      "C:\\Users\\gmrou\\AppData\\Local\\Temp\\ipykernel_9616\\4219890672.py:27: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"INSUF_CARD\"] = data[\"INSUF_CARD\"].replace({\"NON\": 0,\"OUI\":1})\n",
      "C:\\Users\\gmrou\\AppData\\Local\\Temp\\ipykernel_9616\\4219890672.py:28: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"ARTERIOPATHIE\"] = data[\"ARTERIOPATHIE\"].replace({\"NON\": 0,\"OUI\":1})\n",
      "C:\\Users\\gmrou\\AppData\\Local\\Temp\\ipykernel_9616\\4219890672.py:29: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"SYND_APNEE_SOMM\"] = data[\"SYND_APNEE_SOMM\"].replace({\"NON\": 0,\"OUI\":1})\n",
      "C:\\Users\\gmrou\\AppData\\Local\\Temp\\ipykernel_9616\\4219890672.py:30: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"THROMB_VX_PROF\"] = data[\"THROMB_VX_PROF\"].replace({\"NON\": 0,\"OUI\":1})\n",
      "C:\\Users\\gmrou\\AppData\\Local\\Temp\\ipykernel_9616\\4219890672.py:31: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"EMBOL_PULM\"] = data[\"EMBOL_PULM\"].replace({\"NON\": 0,\"OUI\":1})\n",
      "C:\\Users\\gmrou\\AppData\\Local\\Temp\\ipykernel_9616\\4219890672.py:32: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"TB_RYTHME_CARD\"] = data[\"TB_RYTHME_CARD\"].replace({\"NON\": 0,\"OUI\":1})\n",
      "C:\\Users\\gmrou\\AppData\\Local\\Temp\\ipykernel_9616\\4219890672.py:33: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"DEPRESSION\"] = data[\"DEPRESSION\"].replace({\"NON\": 0,\"OUI\":1})\n",
      "C:\\Users\\gmrou\\AppData\\Local\\Temp\\ipykernel_9616\\4219890672.py:34: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"EPILEPSIE\"] = data[\"EPILEPSIE\"].replace({\"NON\": 0,\"OUI\":1})\n",
      "C:\\Users\\gmrou\\AppData\\Local\\Temp\\ipykernel_9616\\4219890672.py:35: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"CANCER\"] = data[\"CANCER\"].replace({\"NON\": 0,\"OUI\":1})\n",
      "C:\\Users\\gmrou\\AppData\\Local\\Temp\\ipykernel_9616\\4219890672.py:36: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"FRISQUVASC_HTA\"] = data[\"FRISQUVASC_HTA\"].replace({\"NON\": 0,\"OUI\":1})\n",
      "C:\\Users\\gmrou\\AppData\\Local\\Temp\\ipykernel_9616\\4219890672.py:37: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"FRISQUVASC_DIAB\"] = data[\"FRISQUVASC_DIAB\"].replace({\"NON\": 0,\"OUI\":1})\n",
      "C:\\Users\\gmrou\\AppData\\Local\\Temp\\ipykernel_9616\\4219890672.py:38: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"FRISQUVASC_HYPCHOL\"] = data[\"FRISQUVASC_HYPCHOL\"].replace({\"NON\": 0,\"OUI\":1})\n",
      "C:\\Users\\gmrou\\AppData\\Local\\Temp\\ipykernel_9616\\4219890672.py:39: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"FRISQUVASC_HYPTRI\"] = data[\"FRISQUVASC_HYPTRI\"].replace({\"NON\": 0,\"OUI\":1})\n",
      "C:\\Users\\gmrou\\AppData\\Local\\Temp\\ipykernel_9616\\4219890672.py:40: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"FRISQUVASC_TABAC\"] = data[\"FRISQUVASC_TABAC\"].replace({\"NON\": 0,\"OUI\":1})\n",
      "C:\\Users\\gmrou\\AppData\\Local\\Temp\\ipykernel_9616\\4219890672.py:41: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"FACTEUR_ALCOOL\"] = data[\"FACTEUR_ALCOOL\"].replace({\"NON\": 0,\"OUI\":1})\n",
      "C:\\Users\\gmrou\\AppData\\Local\\Temp\\ipykernel_9616\\4219890672.py:42: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"ACT_PHYS\"] = data[\"ACT_PHYS\"].replace({\"NON\": 0,\"OUI\":1})\n",
      "C:\\Users\\gmrou\\AppData\\Local\\Temp\\ipykernel_9616\\4219890672.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"PLAINTE_COG_M6\"] = data[\"PLAINTE_COG_M6\"].replace({\"NON\": 0,\"OUI\":1}).astype(\"Int64\",errors=\"ignore\") #\"Int64\" pour forcer les valeurs à etre int64 car à cause de la présence de NaN qui sont des float64, le reste est cast en float64\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing \n",
    "# Data.csv = data complete\n",
    "# data_types.csv =  type + dim + nclass\n",
    "# Missingxx_y.csv = containing the position of the different missing values\n",
    "\n",
    "#Suppression des colones non-nécessaires\n",
    "data = pd.read_csv(\"Big_Data_Strokdem.xlsx\", usecols=lambda x: x not in [\"SYND_TB_COG_M6\",\n",
    "                                                                           \"SYND_TB_COG_M12\",\n",
    "                                                                           \"SYND_TB_COG_M36\",\n",
    "                                                                           \"SYND_TB_COG_M60\",\n",
    "                                                                           \"SUBJID\",\n",
    "                                                                           \"Identifiant_MR\",\n",
    "                                                                           \"NOM_PAT\",\n",
    "                                                                           \"PRENOM_PAT\",\n",
    "                                                                           \"DDN\"])\n",
    "\n",
    "#Récupération de tous les attributs\n",
    "data_features = data.columns\n",
    "\n",
    "\n",
    "\n",
    "# M = 0 et F = 1\n",
    "#NON (NO) = 0 and OUI (YES) = 1\n",
    "#Remplacer les données catégorielle sur le genre en valeur 0 et 1\n",
    "data[\"GENRE\"] = data[\"GENRE\"].replace({\"M\": 0,\"F\":1})\n",
    "data[\"PATHO_CORO\"] = data[\"PATHO_CORO\"].replace({\"NON\": 0,\"OUI\":1})\n",
    "data[\"INSUF_CARD\"] = data[\"INSUF_CARD\"].replace({\"NON\": 0,\"OUI\":1})\n",
    "data[\"ARTERIOPATHIE\"] = data[\"ARTERIOPATHIE\"].replace({\"NON\": 0,\"OUI\":1})\n",
    "data[\"SYND_APNEE_SOMM\"] = data[\"SYND_APNEE_SOMM\"].replace({\"NON\": 0,\"OUI\":1})\n",
    "data[\"THROMB_VX_PROF\"] = data[\"THROMB_VX_PROF\"].replace({\"NON\": 0,\"OUI\":1})\n",
    "data[\"EMBOL_PULM\"] = data[\"EMBOL_PULM\"].replace({\"NON\": 0,\"OUI\":1})\n",
    "data[\"TB_RYTHME_CARD\"] = data[\"TB_RYTHME_CARD\"].replace({\"NON\": 0,\"OUI\":1})\n",
    "data[\"DEPRESSION\"] = data[\"DEPRESSION\"].replace({\"NON\": 0,\"OUI\":1})\n",
    "data[\"EPILEPSIE\"] = data[\"EPILEPSIE\"].replace({\"NON\": 0,\"OUI\":1})\n",
    "data[\"CANCER\"] = data[\"CANCER\"].replace({\"NON\": 0,\"OUI\":1})\n",
    "data[\"FRISQUVASC_HTA\"] = data[\"FRISQUVASC_HTA\"].replace({\"NON\": 0,\"OUI\":1})\n",
    "data[\"FRISQUVASC_DIAB\"] = data[\"FRISQUVASC_DIAB\"].replace({\"NON\": 0,\"OUI\":1})\n",
    "data[\"FRISQUVASC_HYPCHOL\"] = data[\"FRISQUVASC_HYPCHOL\"].replace({\"NON\": 0,\"OUI\":1})\n",
    "data[\"FRISQUVASC_HYPTRI\"] = data[\"FRISQUVASC_HYPTRI\"].replace({\"NON\": 0,\"OUI\":1})\n",
    "data[\"FRISQUVASC_TABAC\"] = data[\"FRISQUVASC_TABAC\"].replace({\"NON\": 0,\"OUI\":1})\n",
    "data[\"FACTEUR_ALCOOL\"] = data[\"FACTEUR_ALCOOL\"].replace({\"NON\": 0,\"OUI\":1})\n",
    "data[\"ACT_PHYS\"] = data[\"ACT_PHYS\"].replace({\"NON\": 0,\"OUI\":1})\n",
    "data[\"PLAINTE_COG_M6\"] = data[\"PLAINTE_COG_M6\"].replace({\"NON\": 0,\"OUI\":1}).astype(\"Int64\",errors=\"ignore\") #\"Int64\" pour forcer les valeurs à etre int64 car à cause de la présence de NaN qui sont des float64, le reste est cast en float64\n",
    "#Il existe des valeurs \"D\" dans la base de donnée, on les remplace par des cases vides. Nous ne connaissons pas la signification de ce \"D\"\n",
    "data = data.replace(to_replace=\"D\",value=np.nan)\n",
    "\n",
    "#Création du csv dans l'étape missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemples de variables catégorielles:\n",
      "('GENRE', 'cat', 2, 2)\n",
      "\n",
      "Exemples de variables numériques positives:\n",
      "('AGE', 'pos', 1, None)\n",
      "('NB_AN_SCOL', 'pos', 1, None)\n",
      "('IQ_CODE_J0', 'pos', 1, None)\n",
      "('IQ_CODE_M6', 'pos', 1, None)\n"
     ]
    }
   ],
   "source": [
    "#Data types\n",
    "    \n",
    "# Création de la liste data_type\n",
    "data_type = []\n",
    "\n",
    "# Variables catégorielles identifiées (converties de NON/OUI ou M/F en 0/1)\n",
    "categorical_vars = [\n",
    "    \"GENRE\", \"PATHO_CORO\", \"INSUF_CARD\", \"ARTERIOPATHIE\", \n",
    "    \"SYND_APNEE_SOMM\", \"THROMB_VX_PROF\", \"EMBOL_PULM\", \n",
    "    \"TB_RYTHME_CARD\", \"DEPRESSION\", \"EPILEPSIE\", \"CANCER\",\n",
    "    \"FRISQUVASC_HTA\", \"FRISQUVASC_DIAB\", \"FRISQUVASC_HYPCHOL\",\n",
    "    \"FRISQUVASC_HYPTRI\", \"FRISQUVASC_TABAC\", \"FACTEUR_ALCOOL\",\n",
    "    \"ACT_PHYS\", \"PLAINTE_COG_M6\"\n",
    "]\n",
    "\n",
    "# Analyser chaque colonne dans data_features\n",
    "for col in data_features:\n",
    "    if col in categorical_vars:\n",
    "        # Pour les variables catégorielles binaires (2 classes: 0 et 1)\n",
    "        data_type.append((col, 'cat', 2, 2))\n",
    "    else:\n",
    "        # Pour les variables numériques positives\n",
    "        data_type.append((col, 'pos', 1, None))\n",
    "\n",
    "# Optionnel: convertir en dictionnaire comme dans l'exemple\n",
    "types_list_d = {}\n",
    "types_list_d['Strokdem'] = data_type\n",
    "\n",
    "types_list = types_list_d['Strokdem']\n",
    "# Afficher les premiers éléments pour vérification\n",
    "print(\"Exemples de variables catégorielles:\")\n",
    "for item in data_type[:5]:\n",
    "    if item[1] == 'cat':\n",
    "        print(item)\n",
    "\n",
    "print(\"\\nExemples de variables numériques positives:\")\n",
    "for item in data_type[:5]:\n",
    "    if item[1] == 'pos':\n",
    "        print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble complet: (202, 47)\n",
      "Taille de l'ensemble d'entraînement: (161, 47) (79.7% des données)\n",
      "Taille de l'ensemble de test: (41, 47) (20.3% des données)\n",
      "\n",
      "Distribution des variables catégorielles dans l'ensemble d'entraînement:\n",
      "GENRE: {0: 0.6024844720496895, 1: 0.39751552795031053}\n",
      "PATHO_CORO: {0: 0.906832298136646, 1: 0.09316770186335403}\n",
      "INSUF_CARD: {0: 0.9813664596273292, 1: 0.018633540372670808}\n",
      "\n",
      "Distribution des variables catégorielles dans l'ensemble de test:\n",
      "GENRE: {0: 0.7073170731707317, 1: 0.2926829268292683}\n",
      "PATHO_CORO: {0: 0.926829268292683, 1: 0.07317073170731707}\n",
      "INSUF_CARD: {0: 0.975609756097561, 1: 0.024390243902439025}\n",
      "    0   1   2   3     4     5     6  7  8  9   ...    37    38    39    40  \\\n",
      "0    0  64  12  48   NaN   NaN   NaN  0  0  0  ...   NaN  30.0   NaN   NaN   \n",
      "1    0  80  17  51  49.0   NaN   NaN  0  0  0  ...   NaN   NaN   NaN   NaN   \n",
      "2    0  71   9  48  48.0  48.0  21.0  0  0  0  ...  28.0  29.0  30.0  29.0   \n",
      "3    1  74  10  48  45.0  51.0   NaN  0  0  0  ...  19.0  27.0  19.0   NaN   \n",
      "4    1  78  10  48   NaN   NaN   NaN  0  0  0  ...   NaN   NaN   NaN   NaN   \n",
      "..  ..  ..  ..  ..   ...   ...   ... .. .. ..  ...   ...   ...   ...   ...   \n",
      "156  1  72   8  52   NaN   NaN   NaN  0  0  0  ...  18.0  22.0   NaN  18.0   \n",
      "157  1  64   9  48  48.0   NaN   NaN  0  0  0  ...  25.0  25.0  28.0  24.0   \n",
      "158  0  60  10  50   NaN   NaN   NaN  1  0  1  ...  12.0  26.0  16.0  27.0   \n",
      "159  0  63   8  46  48.0  48.0   NaN  0  0  0  ...  29.0  28.0  28.0   NaN   \n",
      "160  1  78   8  52  54.0  53.0   NaN  0  0  0  ...  27.0  23.0  26.0   NaN   \n",
      "\n",
      "       41   42   43 44   45    46  \n",
      "0     NaN  0.0  0.0  1  1.0  <NA>  \n",
      "1     NaN  2.0  1.0  2  0.0  <NA>  \n",
      "2     NaN  2.0  1.0  0  0.0     0  \n",
      "3     NaN  1.0  1.0  2  2.0     0  \n",
      "4     NaN  0.0  1.0  1  1.0  <NA>  \n",
      "..    ...  ...  ... ..  ...   ...  \n",
      "156  18.0  2.0  1.0  0  0.0     1  \n",
      "157  23.0  2.0  1.0  0  0.0     0  \n",
      "158   NaN  1.0  1.0  3  4.0     0  \n",
      "159   NaN  1.0  1.0  0  0.0     0  \n",
      "160   NaN  1.0  0.0  0  0.0     1  \n",
      "\n",
      "[161 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "# Importation des bibliothèques nécessaires si ce n'est pas déjà fait\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de test (80% entraînement, 20% test)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Afficher les dimensions des ensembles\n",
    "print(f\"Taille de l'ensemble complet: {data.shape}\")\n",
    "print(f\"Taille de l'ensemble d'entraînement: {train_data.shape} ({train_data.shape[0]/data.shape[0]*100:.1f}% des données)\")\n",
    "print(f\"Taille de l'ensemble de test: {test_data.shape} ({test_data.shape[0]/data.shape[0]*100:.1f}% des données)\")\n",
    "\n",
    "# Vérification rapide des distributions\n",
    "print(\"\\nDistribution des variables catégorielles dans l'ensemble d'entraînement:\")\n",
    "for cat_var in categorical_vars[:3]:  # Afficher seulement les 3 premières variables pour éviter une sortie trop longue\n",
    "    print(f\"{cat_var}: {train_data[cat_var].value_counts(normalize=True).to_dict()}\")\n",
    "\n",
    "print(\"\\nDistribution des variables catégorielles dans l'ensemble de test:\")\n",
    "for cat_var in categorical_vars[:3]:\n",
    "    print(f\"{cat_var}: {test_data[cat_var].value_counts(normalize=True).to_dict()}\")\n",
    "\n",
    "# Sauvegarder les ensembles dans des fichiers CSV (optionnel)\n",
    "train_data.to_csv(\"train_data.csv\", index=False)\n",
    "test_data.to_csv(\"test_data.csv\", index=False)\n",
    "\n",
    "\n",
    "#Suppression de la ligne des noms d'attributs\n",
    "train_data = pd.DataFrame(train_data.values)\n",
    "test_data = pd.DataFrame(test_data.values)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct missing data mask - for data having missing data\n",
    "missing_true_train = pd.DataFrame()\n",
    "for x in list(train_data.columns.values):\n",
    "    missing_true_train[x] = train_data[x].isna().map({True:0,False:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing_true_test = pd.DataFrame()\n",
    "for x in list(test_data.columns.values):\n",
    "    missing_true_test  =  test_data[x].isna().map({True:0,False:1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_dict = {\n",
    "        'Strokdem':{\n",
    "            'batch_size':32,\n",
    "            'model_name':'model_HIVAE_inputDropout',\n",
    "            'dim_z': 5,\n",
    "            'dim_y': 5,\n",
    "            'dim_s': 10,\n",
    "        }\n",
    "        \n",
    "}\n",
    "\n",
    "iterations={\n",
    "    'Strokdem': 50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_directory = '.' # directory where the data, results and networks are stored\n",
    "# set up paths\n",
    "# where the data should be found\n",
    "dataset_path = '{}/data/{}'.format(main_directory,'Strokdem')\n",
    "# where the results will be saved\n",
    "results_path = '{}/results/{}'.format(main_directory,'Strokdemn')\n",
    "# where the networks will be saved\n",
    "network_path = '{}/network/{}'.format(main_directory,'Strokdemn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProjetIG\\VAE_5\\hivae\\graph_new.py:15: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import hivae\n",
    "\n",
    "hivae_obj = hivae.hivae(types_list,network_dict['Strokdem'],results_path=results_path,network_path=network_path)\n",
    "dataset_name = 'Strokdem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types dans train_array: [<class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>]\n"
     ]
    }
   ],
   "source": [
    "# 1. Convertir explicitement les données en types numériques appropriés\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Copier les DataFrames\n",
    "train_data_numeric = train_data.copy()\n",
    "missing_true_train_numeric = missing_true_train.copy() if missing_true_train is not None else None\n",
    "\n",
    "# Convertir chaque colonne au type approprié\n",
    "for i, (col, (name, type_val, dim, nclass)) in enumerate(zip(train_data.columns, types_list)):\n",
    "    if type_val == 'cat':\n",
    "        # Variables catégorielles: convertir en entiers\n",
    "        train_data_numeric[col] = pd.to_numeric(train_data_numeric[col], errors='coerce').fillna(0).astype(int)\n",
    "    else:\n",
    "        # Variables numériques: convertir en float\n",
    "        train_data_numeric[col] = pd.to_numeric(train_data_numeric[col], errors='coerce').fillna(0.0).astype(float)\n",
    "\n",
    "# 2. Convertir en tableaux NumPy\n",
    "train_array = train_data_numeric.values\n",
    "missing_array = missing_true_train_numeric.values.astype(int) if missing_true_train_numeric is not None else None\n",
    "\n",
    "# 3. Vérifier qu'il n'y a plus de chaînes dans les données\n",
    "print(\"Types dans train_array:\", [type(x) for x in np.unique(train_array.flatten())])\n",
    "if np.any([isinstance(x, str) for x in np.unique(train_array.flatten())]):\n",
    "    print(\"ATTENTION: Il reste des chaînes dans les données!\")\n",
    "    \n",
    "    \n",
    "# Version alternative avec traitement plus strict des chaînes\n",
    "def ensure_numeric(array):\n",
    "    \"\"\"Convertit un tableau numpy et s'assure qu'il ne contient que des valeurs numériques\"\"\"\n",
    "    result = np.zeros_like(array, dtype=float)\n",
    "    for i in range(array.shape[0]):\n",
    "        for j in range(array.shape[1]):\n",
    "            try:\n",
    "                result[i, j] = float(array[i, j])\n",
    "            except (ValueError, TypeError):\n",
    "                result[i, j] = 0.0\n",
    "    return result\n",
    "\n",
    "# Convertir les DataFrames en tableaux puis forcer la conversion numérique\n",
    "train_array = ensure_numeric(train_data.values)\n",
    "missing_array = missing_true_train.values.astype(int) if missing_true_train is not None else None\n",
    "\n",
    "# Appeler fit avec ces tableaux strictement numériques\n",
    "hivae_obj.fit(train_array, epochs=iterations[dataset_name], true_missing_mask=missing_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types dans test_array: [<class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Appliquer le même prétraitement aux données de test\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Copier le DataFrame de test\n",
    "test_data_numeric = test_data.copy()\n",
    "missing_true_test_numeric = missing_true_test.copy() if missing_true_test is not None else None\n",
    "\n",
    "# Convertir chaque colonne au type approprié\n",
    "for i, (col, (name, type_val, dim, nclass)) in enumerate(zip(test_data.columns, types_list)):\n",
    "    if type_val == 'cat':\n",
    "        # Variables catégorielles: convertir en entiers\n",
    "        test_data_numeric[col] = pd.to_numeric(test_data_numeric[col], errors='coerce').fillna(0).astype(int)\n",
    "    else:\n",
    "        # Variables numériques: convertir en float\n",
    "        test_data_numeric[col] = pd.to_numeric(test_data_numeric[col], errors='coerce').fillna(0.0).astype(float)\n",
    "\n",
    "# Convertir en tableaux NumPy\n",
    "test_array = test_data_numeric.values\n",
    "missing_test_array = missing_true_test_numeric.values.astype(int) if missing_true_test_numeric is not None else None\n",
    "\n",
    "# Vérifier qu'il n'y a plus de chaînes dans les données\n",
    "print(\"Types dans test_array:\", [type(x) for x in np.unique(test_array.flatten())][:5])\n",
    "\n",
    "# Appeler predict avec ces tableaux\n",
    "(test_data_result, test_data_reconstructed, test_data_decoded, \n",
    " test_data_embedded_z, test_data_embedded_s) = hivae_obj.predict(test_array, \n",
    "                                                               true_missing_mask=missing_test_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_reconstructed = pd.DataFrame(test_data_reconstructed, columns=test_data.columns)\n",
    "test_data_reconstructed.to_csv(\"test_data_reconstructed.csv\", index=False)\n",
    "# Ajouter le nom des colonnes dans la liste data_features\n",
    "test_data_reconstructed.columns = data_features\n",
    "\n",
    "# Sauvegarder le DataFrame reconstruit en fichier Excel\n",
    "test_data_reconstructed.to_excel(\"test_data_reconstructed.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
